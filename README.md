# keerky
The Large-Language Model Operating System.
- https://arxiv.org/html/2404.01744v2
- https://twitter.com/adcock_brett/status/1777004297143603322


## MVP
- Tool-enabled LLM model
- Can ask it to write a program, it will:
- Create a new project in VS Code, open it for you, save the file and run it

## TODO
- Setup Mistral with ollama in this repo
- Toy script that accepts a prompt and generates code to solve that prompt
- Extend it so that it creates a new VS Code project, opens it with this code in a file
- Runs the code in the vscode project
- Landing page with key value proposition, customers, testimonials and other info from: https://twitter.com/sveta_bay/status/1751905577197064647/photo/1

## SPRINKLES
- You can keep giving it commands in the terminal and it will update the github files and run it.
- Chain of thought/improve reasoning
- Has complete control over everything in the operating system
- Retrieval Augmented Generation on all your most recently edited files, session history, bash commands history, browser history
- Local File Management: Assist with content in local files, "Insert sales figures from last Tuesday's Excel file," using local data access
- Intuitive Troubleshooting: When a user encounters a system error or technical issue, the LLM can provide a plain-language explanaition and step by step troubleshooting guidance, tailored to simple language
- Advanced Voice Commands: control devices with complex voice commands, e.g., "Open and start slideshow from slide 10 of yesterday's presentation," using local data processing
- Available globally as a system API
- Programs can register functions for the LLm to use
- Access to all the user's information
- Including session tokens

## SOURCES
- https://campedersen.com/llm-os/
